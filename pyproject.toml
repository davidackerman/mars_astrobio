[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "scientific-pipelines"
version = "0.2.0"
description = "Multi-domain unsupervised ML pipelines for planetary and astronomical data analysis"
readme = "README.md"
requires-python = ">=3.10,<3.13"
license = {text = "BSD-3-Clause"}
authors = [
    {name = "David Ackerman", email = "ackermand@hhmi.org"}
]
keywords = ["mars", "astronomy", "unsupervised-learning", "clustering", "machine-learning", "pytorch", "ctx", "wise", "brown-dwarfs"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering :: Astronomy",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]

# Core dependencies (PyPI)
dependencies = [
    "torch>=2.5.0",
    "torchvision>=0.20.0",
    "numpy>=1.26.0",
    "pillow>=10.0.0",
    "requests>=2.31.0",
    "pyyaml>=6.0",
    "tqdm>=4.66.0",
    "pandas>=2.2.0",
    "matplotlib>=3.8.0",
    "seaborn>=0.13.0",
    "scipy>=1.12.0",
    "scikit-learn>=1.4.0",
    "h5py>=3.10.0",
    "xmltodict>=0.13.0",
    "python-dotenv>=1.0.0",
    "beautifulsoup4>=4.12.0",
    # New dependencies for multi-domain pipelines
    "hdbscan>=0.8.33",        # HDBSCAN clustering
    "umap-learn>=0.5.5",      # UMAP dimensionality reduction
    "timm>=0.9.0",            # PyTorch Image Models (for DINOv2)
    "panoptes-client>=1.6.0", # Zooniverse Panoptes API
    "pyarrow>=14.0.0",        # Parquet file support
    "faiss-cpu>=1.7.4",       # Fast kNN for novelty detection
]

# Optional dependency groups (managed by Pixi - see tool.pixi.feature sections)

[project.urls]
Repository = "https://github.com/davidackerman/mars_astrobio"
Issues = "https://github.com/davidackerman/mars_astrobio/issues"

[project.scripts]
# Backward compatibility - original WATSON scripts
mars-biosig-download = "scientific_pipelines.planetary.mars.watson.scripts:download_main"
mars-biosig-train = "scientific_pipelines.planetary.mars.watson.scripts:train_main"
mars-biosig-predict = "scientific_pipelines.planetary.mars.watson.scripts:predict_main"
# New multi-domain pipeline scripts
ctx-terrain-pipeline = "scientific_pipelines.planetary.mars.ctx.scripts:run_pipeline"
backyard-worlds-pipeline = "scientific_pipelines.astronomy.backyard_worlds.scripts:run_pipeline"

# Pixi configuration
[tool.pixi.project]
channels = ["conda-forge", "pytorch"]
platforms = ["linux-64"]

# Pixi dependencies (conda packages)
[tool.pixi.dependencies]
python = ">=3.10,<3.13"
pytorch = ">=2.0.0"
torchvision = ">=0.15.0"

# PyPI dependencies auto-read from [project.dependencies]
[tool.pixi.pypi-dependencies]
scientific-pipelines = { path = ".", editable = true }

# Development environment with extras
[tool.pixi.feature.dev.pypi-dependencies]
pytest = ">=8.0.0"
pytest-cov = ">=4.1.0"
black = ">=24.0.0"
ruff = ">=0.2.0"
mypy = ">=1.8.0"
pre-commit = ">=3.6.0"

[tool.pixi.feature.notebooks.pypi-dependencies]
jupyter = ">=1.0.0"
jupyterlab = ">=4.0.0"
ipywidgets = ">=8.1.0"
plotly = ">=5.18.0"

# Define environments
[tool.pixi.environments]
default = {features = ["dev"], solve-group = "default"}
notebooks = {features = ["dev", "notebooks"], solve-group = "default"}
prod = {solve-group = "default"}

# Pixi tasks (command shortcuts)
[tool.pixi.tasks]
download-watson = "python scripts/download_data.py --instrument watson --sols 0-100"
download-atlas = "python scripts/download_pds_atlas.py pdsimg-atlas-curl_2026-01-06T01_11_53_944.bat data/raw/watson_browse 8"
download-cheyava = "python scripts/download_pds_atlas.py pdsimg-atlas-curl_2026-01-06T01_11_53_944.bat data/raw/watson_browse 8 --sols cheyava"
download-wildcat = "python scripts/download_pds_atlas.py pdsimg-atlas-curl_2026-01-06T01_11_53_944.bat data/raw/watson_browse 8 --sols wildcat"
download-biosig = "python scripts/download_pds_atlas.py pdsimg-atlas-curl_2026-01-06T01_11_53_944.bat data/raw/watson_browse 8 --sols biosig"
prepare-data = "python scripts/prepare_dataset.py"
train = "python scripts/train.py --config configs/experiments/exp001_watson_baseline.yaml"
test = "pytest tests/ -v --cov=scientific_pipelines"
lint = "ruff check src/ tests/"
format = "black src/ tests/ scripts/"
typecheck = "mypy src/"
notebook = "jupyter lab notebooks/"
# New pipeline tasks
ctx-pipeline = "ctx-terrain-pipeline --config configs/pipelines/ctx_terrain.yaml"
backyard-worlds = "backyard-worlds-pipeline --config configs/pipelines/backyard_worlds.yaml"

# Tool-specific configurations
[tool.black]
line-length = 100
target-version = ['py310', 'py311', 'py312']
include = '\.pyi?$'

[tool.ruff]
line-length = 100
target-version = "py310"
lint.select = ["E", "F", "I", "N", "W", "B"]
lint.ignore = ["E203", "E501"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_functions = "test_*"
addopts = "-v --cov=scientific_pipelines --cov-report=html --cov-report=term"

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
ignore_missing_imports = true

[tool.hatch.build.targets.wheel]
packages = ["src/scientific_pipelines"]
